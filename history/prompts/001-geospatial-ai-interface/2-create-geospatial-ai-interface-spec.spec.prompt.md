---
id: 2
title: Create Geospatial AI Interface Spec
stage: spec
date: 2025-11-22
surface: agent
model: gemini-pro
feature: 001-geospatial-ai-interface
branch: 001-geospatial-ai-interface
user: User
command: /sp.specify 1. Product Overview GeoMind AI is an AI-driven interface that enables geoscientists, data managers, and subsurface engineers to interact with Landmark OpenWorks (Oracle RDBMS) using natural language. The system interprets user queries, converts them into validated SQL, performs secure read/write operations, and returns formatted results. The system is designed as an external intelligence layer that requires no modification to OpenWorks software, only access to its Oracle database schema. 2. Purpose The purpose of GeoMind AI is to: Provide a plain-English query interface to OpenWorks. Reduce the complexity of querying, updating, and managing subsurface data. Ensure complete safety, auditability, and compliance during database operations. Accelerate workflows related to wells, logs, seismic metadata, markers, and interpretation datasets. Serve as an enterprise-scale assistant bridging geoscience expertise with AI automation. 3. Scope 3.1 Included Functional Domains 3.1.1 Natural Language Understanding Interpret plain-English questions and commands. Detect user intent (retrieve, update, insert, edit, metadata). Translate geoscience terminology into OpenWorks schema tables and columns. Resolve ambiguities through follow-up questions. 3.1.2 Schema-Aware SQL Generation Generate contextually correct SQL based on OpenWorks schema. Validate generated SQL against: Table existence Field existence Allowed joins Permission model Reject unsafe or high-risk SQL operations. 3.1.3 Oracle Database Access Execute read operations across all accessible OpenWorks schemas. Perform controlled write/update operations after user approval. Use parameter binding to avoid SQL injection. Log each executed SQL query with timestamp and user ID. 3.1.4 User Interface Chat-based interface for natural interaction. Tabular view for query results. Query preview (SQL + reasoning). Result export (CSV/Excel). Dark mode for geoscientist workflow environments. 3.1.5 Governance & Safety Role-based access control (RBAC). Multi-step approval workflow for sensitive writes. Full audit trail and rollback registry. Safety guardrails to prevent: Schema modifications Invalid writes Unauthorized operations 4. Functional Requirements 4.1 Query Understanding The system must: Accept free-text English input. Determine table(s), constraints, filters, and metrics requested. Identify missing context and ask clarifying questions. Detect when the user requests edits and enforce confirmation. 4.2 SQL Generation & Validation Generate SQL aligned with the Oracle OpenWorks schema. Validate SQL using: Schema introspection engine Permission model Safety rules Reject or request clarification for ambiguous queries. 4.3 Execution Logic Route SELECT queries immediately if safe. Require confirmation before UPDATE/INSERT operations. Require admin approval for sensitive updates (optional). Execute queries against Oracle via secure DB connection. Store results in temporary cache for faster repeated queries. 4.4 Audit & Traceability Each operation must have: User identity Timestamp Structured SQL log text Affected tables and rows Execution duration 4.5 User Output System must return: Well-formatted responses Complete data tables Summaries for large datasets SQL explanation Error messages that are descriptive but secure (no DB leaks) 5. Non-Functional Requirements 5.1 Performance Handle 1000+ concurrent chat sessions. Sub-2 second response time for cached/optimized queries. Optimized pagination for large tables. 5.2 Scalability Stateless microservices. Horizontal scaling via Kubernetes. Independent scaling for: AI inference DB Gateway UI backend 5.3 Reliability Automatic retries for transient Oracle errors. Graceful failover for AI model unavailability. Zero data loss during operations. 5.4 Security Enforced user authentication (OIDC/SSO). Oracle credentials stored in secure vault. No direct SQL entry allowed from user. All SQL must be LLM-and-rule-validated. 5.5 Compliance Full audit logs per company and regulatory policies. Configurable role permissions aligned with subsurface data governance. 6. System Architecture 6.1 Core Components AI Orchestrator Intent classification SQL generation Query reasoning Schema/Ontology Engine Stores OpenWorks schema structure Synonym mapping (e.g., "MD" = "MEASURED_DEPTH") Table and column validation SQL Safety Validator Detects dangerous operations Blocks unapproved statements Enforces RBAC Oracle Data Gateway Executes final validated SQL Handles parameterized queries Logs results Chat Application Backend Session management Tokenization Result caching Frontend Web App AI chat UI Tabs for schema, history, exports SQL preview window 7. Dependencies 7.1 Technology Stack Frontend: Next.js, React, Tailwind Backend: FastAPI or Node.js (NestJS) AI Pipeline: Python, LangChain / LlamaIndex Database: Oracle 19c (OpenWorks) Vector Storage: pgvector or Chroma Infra: Docker, Kubernetes Auth: Auth0 / Azure AD / Keycloak Logging: Elastic Stack / Loki / Grafana 8. User Experience (UX) Principles 8.1 Conversational Simplicity Never overwhelm the user. Offer options, hints, and suggestions. 8.2 Transparency Always show SQL and reasoning. 8.3 Speed Deliver fast UI interactions. Preload common schema terms. 8.4 Professional Communication Use technical but clear responses. Explain uncertainties. 9. Success Metrics 9.1 Technical KPIs SQL accuracy > 95% Error rate < 1% Query latency < 2s 9.2 User Adoption KPIs Weekly active users Number of queries executed Reduction in manual SQL writing 9.3 Business KPIs Time saved per geoscientist per week Fewer data quality errors Faster OpenWorks data management workflows 10. Evolution Roadmap Phase 1 â€“ MVP Chat â†’ SQL â†’ Oracle Read-only operations Ontology + schema mapping SQL preview Basic UI Phase 2 â€“ Full CRUD & Governance Update/insert workflows Role-based controls Full auditing Data quality assistant Phase 3 â€“ Advanced AI Well log QC agent Seismic metadata intelligence Cross-platform (Petrel, OSDU) connectors Predictive query engine"
labels: ["spec"]
links:
  spec: ./specs/001-geospatial-ai-interface/spec.md
  ticket: null
  adr: null
  pr: null
files:
  - specs/001-geospatial-ai-interface/spec.md
  - specs/001-geospatial-ai-interface/checklists/requirements.md
tests:

---

## Prompt

1. Product Overview GeoMind AI is an AI-driven interface that enables geoscientists, data managers, and subsurface engineers to interact with Landmark OpenWorks (Oracle RDBMS) using natural language. The system interprets user queries, converts them into validated SQL, performs secure read/write operations, and returns formatted results. The system is designed as an external intelligence layer that requires no modification to OpenWorks software, only access to its Oracle database schema. 2. Purpose The purpose of GeoMind AI is to: Provide a plain-English query interface to OpenWorks. Reduce the complexity of querying, updating, and managing subsurface data. Ensure complete safety, auditability, and compliance during database operations. Accelerate workflows related to wells, logs, seismic metadata, markers, and interpretation datasets. Serve as an enterprise-scale assistant bridging geoscience expertise with AI automation. 3. Scope 3.1 Included Functional Domains 3.1.1 Natural Language Understanding Interpret plain-English questions and commands. Detect user intent (retrieve, update, insert, edit, metadata). Translate geoscience terminology into OpenWorks schema tables and columns. Resolve ambiguities through follow-up questions. 3.1.2 Schema-Aware SQL Generation Generate contextually correct SQL based on OpenWorks schema. Validate generated SQL against: Table existence Field existence Allowed joins Permission model Reject unsafe or high-risk SQL operations. 3.1.3 Oracle Database Access Execute read operations across all accessible OpenWorks schemas. Perform controlled write/update operations after user approval. Use parameter binding to avoid SQL injection. Log each executed SQL query with timestamp and user ID. 3.1.4 User Interface Chat-based interface for natural interaction. Tabular view for query results. Query preview (SQL + reasoning). Result export (CSV/Excel). Dark mode for geoscientist workflow environments. 3.1.5 Governance & Safety Role-based access control (RBAC). Multi-step approval workflow for sensitive writes. Full audit trail and rollback registry. Safety guardrails to prevent: Schema modifications Invalid writes Unauthorized operations 4. Functional Requirements 4.1 Query Understanding The system must: Accept free-text English input. Determine table(s), constraints, filters, and metrics requested. Identify missing context and ask clarifying questions. Detect when the user requests edits and enforce confirmation. 4.2 SQL Generation & Validation Generate SQL aligned with the Oracle OpenWorks schema. Validate SQL using: Schema introspection engine Permission model Safety rules Reject or request clarification for ambiguous queries. 4.3 Execution Logic Route SELECT queries immediately if safe. Require confirmation before UPDATE/INSERT operations. Require admin approval for sensitive updates (optional). Execute queries against Oracle via secure DB connection. Store results in temporary cache for faster repeated queries. 4.4 Audit & Traceability Each operation must have: User identity Timestamp Structured SQL log text Affected tables and rows Execution duration 4.5 User Output System must return: Well-formatted responses Complete data tables Summaries for large datasets SQL explanation Error messages that are descriptive but secure (no DB leaks) 5. Non-Functional Requirements 5.1 Performance Handle 1000+ concurrent chat sessions. Sub-2 second response time for cached/optimized queries. Optimized pagination for large tables. 5.2 Scalability Stateless microservices. Horizontal scaling via Kubernetes. Independent scaling for: AI inference DB Gateway UI backend 5.3 Reliability Automatic retries for transient Oracle errors. Graceful failover for AI model unavailability. Zero data loss during operations. 5.4 Security Enforced user authentication (OIDC/SSO). Oracle credentials stored in secure vault. No direct SQL entry allowed from user. All SQL must be LLM-and-rule-validated. 5.5 Compliance Full audit logs per company and regulatory policies. Configurable role permissions aligned with subsurface data governance. 6. System Architecture 6.1 Core Components AI Orchestrator Intent classification SQL generation Query reasoning Schema/Ontology Engine Stores OpenWorks schema structure Synonym mapping (e.g., "MD" = "MEASURED_DEPTH") Table and column validation SQL Safety Validator Detects dangerous operations Blocks unapproved statements Enforces RBAC Oracle Data Gateway Executes final validated SQL Handles parameterized queries Logs results Chat Application Backend Session management Tokenization Result caching Frontend Web App AI chat UI Tabs for schema, history, exports SQL preview window 7. Dependencies 7.1 Technology Stack Frontend: Next.js, React, Tailwind Backend: FastAPI or Node.js (NestJS) AI Pipeline: Python, LangChain / LlamaIndex Database: Oracle 19c (OpenWorks) Vector Storage: pgvector or Chroma Infra: Docker, Kubernetes Auth: Auth0 / Azure AD / Keycloak Logging: Elastic Stack / Loki / Grafana 8. User Experience (UX) Principles 8.1 Conversational Simplicity Never overwhelm the user. Offer options, hints, and suggestions. 8.2 Transparency Always show SQL and reasoning. 8.3 Speed Deliver fast UI interactions. Preload common schema terms. 8.4 Professional Communication Use technical but clear responses. Explain uncertainties. 9. Success Metrics 9.1 Technical KPIs SQL accuracy > 95% Error rate < 1% Query latency < 2s 9.2 User Adoption KPIs Weekly active users Number of queries executed Reduction in manual SQL writing 9.3 Business KPIs Time saved per geoscientist per week Fewer data quality errors Faster OpenWorks data management workflows 10. Evolution Roadmap Phase 1 â€“ MVP Chat â†’ SQL â†’ Oracle Read-only operations Ontology + schema mapping SQL preview Basic UI Phase 2 â€“ Full CRUD & Governance Update/insert workflows Role-based controls Full auditing Data quality assistant Phase 3 â€“ Advanced AI Well log QC agent Seismic metadata intelligence Cross-platform (Petrel, OSDU) connectors Predictive query engine"

## Response snapshot

I have successfully created the feature specification for GeoMind AI Core, including user scenarios, functional requirements, key entities, and measurable success criteria. I have also updated the corresponding requirements checklist to reflect the identified edge cases.

## Outcome

- âœ… Impact: The feature specification for GeoMind AI Core has been created and validated.
- ðŸ§ª Tests: No tests were run.
- ðŸ“ Files: 
  - `specs/001-geospatial-ai-interface/spec.md` was created and updated.
  - `specs/001-geospatial-ai-interface/checklists/requirements.md` was created and updated.
  - `history/prompts/001-geospatial-ai-interface/2-create-geospatial-ai-interface-spec.spec.prompt.md` was created.
- ðŸ” Next prompts: The user can now proceed with architectural planning (`/sp.plan`).
- ðŸ§  Reflection: Encountered difficulties with `read_file` truncation and `replace` tool sensitivity, necessitating a full file rewrite to resolve the edge case update.

## Evaluation notes (flywheel)

- Failure modes observed: `read_file` truncation, `replace` tool sensitivity to exact string matching.
- Graders run and results (PASS/FAIL): N/A
- Prompt variant (if applicable): N/A
- Next experiment (smallest change to try): Investigate robust file content manipulation methods for large files or complex replacements, perhaps by streaming or line-by-line processing if `read_file` continues to truncate.
